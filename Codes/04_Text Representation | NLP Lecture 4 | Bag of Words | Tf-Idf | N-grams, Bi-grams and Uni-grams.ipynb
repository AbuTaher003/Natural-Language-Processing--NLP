{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71707872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ffed993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text':['People watch campusx','Campusx watch Campusx', 'People write comment', 'Campusx write comment'], 'output':[1,1,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12cc17e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Campusx watch Campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   People watch campusx       1\n",
       "1  Campusx watch Campusx       1\n",
       "2   People write comment       0\n",
       "3  Campusx write comment       0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2cfdd026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Bag of Words\n",
    "\n",
    "bow = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30b6c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7919f144",
   "metadata": {},
   "source": [
    "- ```Here the numbers indicate the order of the words in the vocabolary list.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66cad216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]\n",
      " [2 0 0 1 0]\n",
      " [0 1 1 0 1]\n",
      " [1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "313ef981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can test with new sentences.\n",
    "\n",
    "cv.transform(['Campusx write and watch comment']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ecc18",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b3218e",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c7c97c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b303cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_gram = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a3ab3b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch': 2, 'watch campusx': 4, 'campusx watch': 0, 'people write': 3, 'write comment': 5, 'campusx write': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3a36f",
   "metadata": {},
   "source": [
    "- ```Here the vocabulary is generated taking two words at the same time.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d9e1d9bb",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# if we set the range to (1,2) it will consider both unigrams and bigrams.\n",
    "\n",
    "cv = CountVectorizer(ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02817fbe",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "uni_bi_both = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86bad57f",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 4, 'watch': 7, 'campusx': 0, 'people watch': 5, 'watch campusx': 8, 'campusx watch': 1, 'write': 9, 'comment': 3, 'people write': 6, 'write comment': 10, 'campusx write': 2}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6aa6d90",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd611e6a",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# we can do similar for trigrams by setting ngram_range = (3,3)\n",
    "\n",
    "cv = CountVectorizer(ngram_range = (3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef14324c",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "trigrams = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "65d52642",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch campusx': 2, 'campusx watch campusx': 0, 'people write comment': 3, 'campusx write comment': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c024e",
   "metadata": {},
   "source": [
    "# Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5909ad93",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17bc4a87",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ab49f7f",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8e67688a",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "539768d3",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49681612 0.         0.61366674 0.61366674 0.        ]\n",
      " [0.8508161  0.         0.         0.52546357 0.        ]\n",
      " [0.         0.57735027 0.57735027 0.         0.57735027]\n",
      " [0.49681612 0.61366674 0.         0.         0.61366674]]\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf.transform(df['text']).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18960ab3",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
